# EMOTISENSE AI ğŸ§ 

**Multimodal Emotion Recognition using Audio + Face**

A real-time emotion monitoring system that combines facial emotion detection and audio stress analysis to provide comprehensive emotional insights.

## ğŸš€ Quick Start

Run the application in **1 command**:

```bash
# Install dependencies and run
pip install -r requirements.txt && streamlit run app.py
```

The application will open in your browser at `http://localhost:8501`

## ğŸ“ Project Structure

```
EMOTISENSE-AI/
â”œâ”€â”€ app.py                          # Main Streamlit application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                      # This file
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ config.py                  # Configuration settings
â”‚   â”œâ”€â”€ utils.py                   # Utility functions
â”‚   â”œâ”€â”€ webcam/
â”‚   â”‚   â”œâ”€â”€ camera.py              # Camera capture
â”‚   â”‚   â””â”€â”€ face_emotion.py        # Face emotion detection
â”‚   â”œâ”€â”€ audio/
â”‚   â”‚   â”œâ”€â”€ mic_capture.py         # Microphone capture
â”‚   â”‚   â””â”€â”€ audio_emotion.py       # Audio stress analysis
â”‚   â”œâ”€â”€ fusion/
â”‚   â”‚   â””â”€â”€ fusion_engine.py       # Multimodal fusion
â”‚   â”œâ”€â”€ dashboard/
â”‚   â”‚   â”œâ”€â”€ ui_components.py       # UI components
â”‚   â”‚   â””â”€â”€ plots.py               # Visualization charts
â”‚   â”œâ”€â”€ logger/
â”‚   â”‚   â”œâ”€â”€ session_logger.py      # Session logging
â”‚   â”‚   â””â”€â”€ report_generator.py    # PDF report generation
â”‚   â””â”€â”€ fallback/
â”‚       â””â”€â”€ rule_based.py          # Simulation/fallback mode
â”œâ”€â”€ data/
â”‚   â””â”€â”€ sample_sessions/
â”‚       â””â”€â”€ demo_session.csv       # Sample session data
â””â”€â”€ outputs/
    â”œâ”€â”€ session_logs/              # Session CSV files
    â””â”€â”€ reports/                   # Generated PDF reports
```

## ğŸ¯ Features

### Core Functionality
- **Real-time Face Emotion Detection** (6 emotions: happy, sad, angry, fear, surprise, neutral)
- **Audio Stress Analysis** from microphone input
- **Multimodal Fusion Engine** combining face and audio data
- **Live Dashboard** with real-time metrics and alerts
- **Session Logging** with CSV export
- **PDF Report Generation** with insights and recommendations

### Dashboard Tabs
1. **Live Dashboard**: Real-time monitoring with video feed, metrics cards, and charts
2. **Session Report**: Comprehensive analysis with statistics and export options
3. **About**: Project information and technology stack

### Fallback Features
- **Simulation Mode**: Works without camera/microphone
- **Hardware Failure Handling**: Automatic fallback to simulated data
- **Robust Error Handling**: Graceful degradation when components fail

## ğŸ› ï¸ Technology Stack

- **Frontend**: Streamlit
- **Computer Vision**: OpenCV, FER (Facial Emotion Recognition)
- **Audio Processing**: sounddevice, librosa
- **Data Analysis**: pandas, numpy
- **Visualization**: plotly
- **Reports**: reportlab
- **Backup Detection**: DeepFace (fallback for FER)

## ğŸ“Š Metrics Provided

### Primary Metrics
- **Stress Level** (0-1): Combined face negative emotions + audio stress
- **Engagement** (0-1): Positive emotions adjusted by stress level
- **Confusion** (0-1): Emotion variance + moderate stress indicator
- **Confidence** (0-1): Inverse of stress and confusion

### Emotional States
- Stressed, Engaged, Calm, Positive, Negative, Neutral

### Audio Features
- RMS Energy, Zero Crossing Rate, MFCC coefficients, Spectral Centroid

## ğŸ® Usage Instructions

### Starting a Session
1. Launch the application: `streamlit run app.py`
2. Click **"Start Session"** in the sidebar
3. Allow camera and microphone permissions when prompted
4. Monitor real-time emotions in the Live Dashboard

### Simulation Mode
- Toggle **"Simulation Mode"** if camera/microphone unavailable
- Generates realistic emotion patterns for demonstration
- Perfect for testing and demos without hardware

### Generating Reports
1. Stop the active session
2. Navigate to **"Session Report"** tab
3. View statistics and charts
4. Export as CSV or generate PDF report

## ğŸ”§ Configuration

Key settings in `src/config.py`:

```python
# Audio settings
AUDIO_SAMPLE_RATE = 16000
AUDIO_CHUNK_DURATION = 2.0

# Video settings  
VIDEO_WIDTH = 640
VIDEO_HEIGHT = 480

# Thresholds
STRESS_THRESHOLD = 0.7
ALERT_DURATION = 5  # seconds

# Fusion weights
FACE_WEIGHT = 0.6
AUDIO_WEIGHT = 0.4
```

## ğŸš¨ Alerts & Monitoring

- **High Stress Alert**: Triggered when stress > 0.7 for 5+ seconds
- **Real-time Timeline**: Shows last 60 seconds of emotion data
- **Stress Gauge**: Visual stress level indicator with color coding
- **Emotion Breakdown**: Detailed face emotion percentages

## ğŸ“ˆ Output Files

### Session Logs
- Location: `outputs/session_logs/`
- Format: `session_{id}_{timestamp}.csv`
- Contains: Timestamp, emotions, stress scores, fused metrics

### PDF Reports
- Location: `outputs/reports/`
- Format: `emotion_report_{id}_{timestamp}.pdf`
- Contains: Session stats, charts, recommendations

## ğŸ”„ Fallback Mechanisms

1. **Camera Failure**: Uses simulated face emotions with realistic patterns
2. **Microphone Failure**: Generates stress scores based on last known values + noise
3. **Library Errors**: Graceful degradation with default values
4. **Complete Simulation**: Toggle for full demo mode without hardware

## ğŸ› Troubleshooting

### Common Issues

**Camera not working:**
- Enable "Simulation Mode" in sidebar
- Check camera permissions in browser
- Ensure no other applications are using the camera

**Microphone not detected:**
- Application automatically falls back to simulated audio
- Check microphone permissions
- Verify microphone is not muted

**Installation errors:**
```bash
# If librosa installation fails
pip install librosa --no-deps
pip install numba

# If sounddevice fails  
pip install sounddevice --upgrade
```

## ğŸ“ License

This project is open source and available under the MIT License.


---


## ğŸ‘¨â€ğŸ’» Author

**Danish** â€” B.Tech Artificial Intelligence and Data Science 

Hackathon Project: **SRM IST Ã— NOOBTRON â€” NOOB HACKFEST**



## ğŸ‘¥ Team Members â€” PRIMELOGIX

- **Danish M** â€” AI/ML Developer & Integration  
  Implemented the core emotion pipeline (face + audio processing), multimodal fusion logic, and integrated key modules into the working application.

- **Chidarth H** â€” UI/UX & Dashboard Support  
  Supported dashboard layout planning, user flow design, and UI feature suggestions for live monitoring.

- **Deepban T** â€” Research & Feature Design  
  Worked on problem research, identifying real-world use cases, and defining feature requirements for a practical solution.

- **Jothik Rithin Bio J** â€” Testing & Validation  
  Contributed to testing the application workflow, identifying edge cases, and improving demo stability.

- **Deepak T A** â€” Documentation & Presentation  
  Assisted with README preparation, pitch content structuring, and hackathon submission formatting.





---

**Built for hackathons, designed for impact.** ğŸš€

